# ğŸª Google Antigravity Workspace Template (Enterprise Edition)

Language: [English](README.md) | [ä¸­æ–‡](README_CN.md) | [EspaÃ±ol](README_ES.md)

![License](https://img.shields.io/badge/License-MIT-green)
![Gemini](https://img.shields.io/badge/AI-Gemini_2.0_Flash-blue)
![Architecture](https://img.shields.io/badge/Architecture-Event_Driven-purple)
![Memory](https://img.shields.io/badge/Context-Infinite-orange)

Welcome to the **Antigravity Workspace Template**. This is a production-grade starter kit for building autonomous agents on the Google Antigravity platform, fully compliant with **Antigravity Official Documentation**â€”and proudly "Anti-LangChain" thanks to its minimal, transparent architecture.


## ğŸŒŸ Project Philosophy

In an era rich with AI IDEs, I wanted to achieve an enterprise-grade architecture with just **Clone -> Rename -> Prompt**.

This project leverages the IDE's context awareness (via `.cursorrules` and `.antigravity/rules.md`) to embed a complete **Cognitive Architecture** directly into the project files.

When you open this project, your IDE is no longer just an editor; it transforms into a **"Knowledgeable" Architect**.

### Why do we need a "Thinking" Scaffold?

When using Google Antigravity or Cursor for AI development, I found a pain point:

**IDEs and models are powerful, but "empty projects" are weak.**

Every time we start a new project, we repeat boring configurations:
- "Should my code go in src or app?"
- "How do I define tool functions so Gemini recognizes them?"
- "How do I make the AI remember context?"

This repetitive labor is a waste of creativity. My ideal workflow is: **Git Clone -> IDE already knows what to do.**

So I created this project: **Antigravity Workspace Template**.

## ğŸ§  Core Philosophy: Artifact-First

This workspace enforces the **Artifact-First** protocol. The Agent does not just write code; it produces tangible outputs (Artifacts) for every complex task.

1. **Planning**: `artifacts/plan_[task_id].md` is created before coding.
2. **Evidence**: Logs and test outputs are saved to `artifacts/logs/`.
3. **Visuals**: UI changes generate screenshot artifacts.

## ğŸ›¸ How It Works

The agent follows a strict "Think-Act-Reflect" loop, simulating the cognitive process of Gemini 3.

```mermaid
sequenceDiagram
    participant User
    participant Agent as ğŸ¤– GeminiAgent
    participant Memory as ğŸ§  Memory
    participant Tools as ğŸ› ï¸ Tools
    participant Artifacts as ğŸ“‚ Artifacts

    User->>Agent: "Refactor Authentication"
    activate Agent
    
    Agent->>Artifacts: Create Implementation Plan
    
    Note over Agent: <thought> Deep Think Process </thought>
    Agent->>Agent: Formulate Strategy
    
    Agent->>Tools: Execute Tool (code_edit)
    activate Tools
    Tools-->>Agent: Result
    deactivate Tools
    
    Agent->>Artifacts: Save Logs/Evidence
    
    Agent-->>User: Final Report (Walkthrough)
    deactivate Agent
```

## ğŸ”¥ Killer Features

- ğŸ§  **Infinite Memory Engine**: Recursive summarization automatically compresses history. Context limits are a thing of the past.
- ğŸ› ï¸ **Universal Tool Protocol**: Generic ReAct pattern. Just register any Python function in `available_tools`, and the Agent learns to use it.
- âš¡ï¸ **Gemini Native**: Optimized for Gemini 2.0 Flash's speed and function calling capabilities.
- ğŸ”Œ **External LLM (OpenAI-format)**: Call any OpenAI-compatible API via the built-in `call_openai_chat` tool (supports OpenAI/Azure/Ollama).

## ğŸš€ Quick Start

### Local Development
1. **Install Dependencies**:
    ```bash
    pip install -r requirements.txt
    ```
2. **Run the Agent**:
    ```bash
    python src/agent.py
    ```

### Docker Deployment
1. **Build & Run**:
    ```bash
    docker-compose up --build
    ```

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ .antigravity/       # ğŸ›¸ Official Antigravity Config
â”‚  â””â”€â”€ rules.md        # Agent Rules & Permissions
â”œâ”€â”€ artifacts/          # ğŸ“‚ Agent Outputs (Plans, Logs, Visuals)
â”œâ”€â”€ .context/           # AI Knowledge Base
â”œâ”€â”€ .github/            # CI/CD Workflows
â”œâ”€â”€ src/                # Source Code
â”‚  â”œâ”€â”€ agent.py        # Main Agent Logic
â”‚  â”œâ”€â”€ config.py       # Settings Management
â”‚  â”œâ”€â”€ memory.py       # JSON Memory Manager
â”‚  â””â”€â”€ tools/          # Agent Tools
â”œâ”€â”€ tests/              # Test Suite
â”œâ”€â”€ .cursorrules        # Compatibility Pointer
â”œâ”€â”€ Dockerfile          # Production Build
â”œâ”€â”€ docker-compose.yml  # Local Dev Setup
â””â”€â”€ mission.md          # Agent Objective
```

## ğŸš€ The "Zero-Config" Workflow

Stop writing long system prompts. This workspace pre-loads the AI's cognitive architecture for you.

### Step 1: Clone & Rename (The "Mold")
Treat this repository as a factory mold. Clone it, then rename the folder to your project name.
```bash
git clone https://github.com/study8677/antigravity-workspace-template.git my-agent-project
cd my-agent-project
# Now you are ready. No setup required.
```

### Step 2: The Magic Moment âš¡ï¸
Open the folder in Cursor or Google Antigravity.
- ğŸ‘€ **Watch**: The IDE automatically detects `.cursorrules`.
- ğŸ§  **Load**: The AI silently ingests the "Antigravity Expert" persona from `.antigravity/rules.md`.

### Step 3: Just Prompt (No Instructions Needed)
You don't need to tell the AI to "be careful" or "use the src folder". It's already brainwashed to be a Senior Engineer.

**Old Way (Manual Prompting)**:
> "Please write a snake game. Make sure to use modular code. Put files in src. Don't forget comments..."

**The Antigravity Way**:
> "Build a snake game."

The AI will automatically:
1. ğŸ›‘ **Pause**: "According to protocols, I must plan first."
2. ğŸ“„ **Document**: Generates `artifacts/plan_snake.md`.
3. ğŸ”¨ **Build**: Writes modular code into `src/game/` with full Google-style docstrings.

## ğŸ—ºï¸ Roadmap

- [x] **Phase 1: Foundation** (Scaffold, Config, Memory)
- [x] **Phase 2: DevOps** (Docker, CI/CD)
- [x] **Phase 3: Antigravity Compliance** (Rules, Artifacts)
- [x] **Phase 4: Advanced Memory** (Summary Buffer Implemented âœ…)
- [x] **Phase 5: Cognitive Architecture** (Generic Tool Dispatch Implemented âœ…)
- [x] **Phase 6: Dynamic Discovery** (Auto Tool & Context Loading âœ…)
- [x] **Phase 7: Multi-Agent Swarm** (Router-Worker Orchestration âœ…)

## ğŸ”¥ New: True Zero-Config Tool & Context Loading

**No more manual imports!** The agent now automatically discovers:

### ğŸ› ï¸ Auto Tool Discovery
Drop any Python file into `src/tools/` and the agent instantly knows how to use it:

```python
# src/tools/my_custom_tool.py
def analyze_sentiment(text: str) -> str:
    """Analyzes the sentiment of given text.
    
    Args:
        text: The text to analyze.
        
    Returns:
        Sentiment score and analysis.
    """
    # Your implementation
    return "Positive sentiment detected!"
```

**That's it!** No need to edit `agent.py`. Just restart and the tool is available.

### ğŸ“š Auto Context Loading
Add knowledge files to `.context/` and they're automatically injected:

```bash
echo "# Project Rules\nUsefriendly language." > .context/project_rules.md
```

The agent will follow these rules immediately on next run.

## ğŸ”¥ New: Multi-Agent Swarm Protocol

**Collaborate at scale!** The swarm enables multiple specialist agents to work together:

### ğŸª Architecture: Router-Worker Pattern

```mermaid
graph TD
    User[User Task] --> Router[ğŸ§­ Router Agent]
    Router --> Coder[ğŸ’» Coder Agent]
    Router --> Reviewer[ğŸ” Reviewer Agent]
    Router --> Researcher[ğŸ“š Researcher Agent]
    Coder --> Router
    Reviewer --> Router
    Researcher --> Router
    Router --> Result[ğŸ“Š Synthesized Result]
```

**Specialist Agents:**
- **Router**: Analyzes tasks, delegates to specialists, synthesizes results
- **Coder**: Writes clean, well-documented code
- **Reviewer**: Checks quality, security, best practices
- **Researcher**: Gathers information and insights

### ğŸš€ Usage

**Run the interactive demo:**
```bash
python -m src.swarm_demo
```

**Use in your code:**
```python
from src.swarm import SwarmOrchestrator

swarm = SwarmOrchestrator()
result = swarm.execute("Build a calculator and review it for security")
print(result)
```

**Example output:**
```
ğŸ§­ [Router] Analyzing task...
ğŸ“¤ [Router â†’ Coder] Build a calculator
ğŸ’» [Coder] Creating calculator implementation...
âœ… [Coder] Done!
The agent follows a strict "Think-Act-Reflect" loop, simulating the cognitive process of Gemini 3.

```mermaid
sequenceDiagram
    participant User
    participant Agent as ğŸ¤– GeminiAgent
    participant Memory as ğŸ§  Memory
    participant Tools as ğŸ› ï¸ Tools
    participant Artifacts as ğŸ“‚ Artifacts

    User->>Agent: "Refactor Authentication"
    activate Agent
    
    Agent->>Artifacts: Create Implementation Plan
    
    Note over Agent: <thought> Deep Think Process </thought>
    Agent->>Agent: Formulate Strategy
    
    Agent->>Tools: Execute Tool (code_edit)
    activate Tools
    Tools-->>Agent: Result
    deactivate Tools
    
    Agent->>Artifacts: Save Logs/Evidence
    
    Agent-->>User: Final Report (Walkthrough)
    deactivate Agent
```

## ğŸ”¥ Killer Features

- ğŸ§  **Infinite Memory Engine**: Recursive summarization automatically compresses history. Context limits are a thing of the past.
- ğŸ› ï¸ **Universal Tool Protocol**: Generic ReAct pattern. Just register any Python function in `available_tools`, and the Agent learns to use it.
- âš¡ï¸ **Gemini Native**: Optimized for Gemini 2.0 Flash's speed and function calling capabilities.

## ğŸš€ Quick Start

### Local Development
1. **Install Dependencies**:
    ```bash
    pip install -r requirements.txt
    ```
2. **Run the Agent**:
    ```bash
    python src/agent.py
    ```

### Docker Deployment
1. **Build & Run**:
    ```bash
    docker-compose up --build
    ```

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ .antigravity/       # ğŸ›¸ Official Antigravity Config
â”‚  â””â”€â”€ rules.md        # Agent Rules & Permissions
â”œâ”€â”€ artifacts/          # ğŸ“‚ Agent Outputs (Plans, Logs, Visuals)
â”œâ”€â”€ .context/           # AI Knowledge Base
â”œâ”€â”€ .github/            # CI/CD Workflows
â”œâ”€â”€ src/                # Source Code
â”‚  â”œâ”€â”€ agent.py        # Main Agent Logic
â”‚  â”œâ”€â”€ config.py       # Settings Management
â”‚  â”œâ”€â”€ memory.py       # JSON Memory Manager
â”‚  â””â”€â”€ tools/          # Agent Tools
â”œâ”€â”€ tests/              # Test Suite
â”œâ”€â”€ .cursorrules        # Compatibility Pointer
â”œâ”€â”€ Dockerfile          # Production Build
â”œâ”€â”€ docker-compose.yml  # Local Dev Setup
â””â”€â”€ mission.md          # Agent Objective
```

## ğŸš€ The "Zero-Config" Workflow

Stop writing long system prompts. This workspace pre-loads the AI's cognitive architecture for you.

### Step 1: Clone & Rename (The "Mold")
Treat this repository as a factory mold. Clone it, then rename the folder to your project name.
```bash
git clone https://github.com/study8677/antigravity-workspace-template.git my-agent-project
cd my-agent-project
# Now you are ready. No setup required.
```

### Step 2: The Magic Moment âš¡ï¸
Open the folder in Cursor or Google Antigravity.
- ğŸ‘€ **Watch**: The IDE automatically detects `.cursorrules`.
- ğŸ§  **Load**: The AI silently ingests the "Antigravity Expert" persona from `.antigravity/rules.md`.

### Step 3: Just Prompt (No Instructions Needed)
You don't need to tell the AI to "be careful" or "use the src folder". It's already brainwashed to be a Senior Engineer.

**Old Way (Manual Prompting)**:
> "Please write a snake game. Make sure to use modular code. Put files in src. Don't forget comments..."

**The Antigravity Way**:
> "Build a snake game."

The AI will automatically:
1. ğŸ›‘ **Pause**: "According to protocols, I must plan first."
2. ğŸ“„ **Document**: Generates `artifacts/plan_snake.md`.
3. ğŸ”¨ **Build**: Writes modular code into `src/game/` with full Google-style docstrings.

## ğŸ—ºï¸ Roadmap

- [x] **Phase 1: Foundation** (Scaffold, Config, Memory)
- [x] **Phase 2: DevOps** (Docker, CI/CD)
- [x] **Phase 3: Antigravity Compliance** (Rules, Artifacts)
- [x] **Phase 4: Advanced Memory** (Summary Buffer Implemented âœ…)
- [x] **Phase 5: Cognitive Architecture** (Generic Tool Dispatch Implemented âœ…)
- [x] **Phase 6: Dynamic Discovery** (Auto Tool & Context Loading âœ…)
- [x] **Phase 7: Multi-Agent Swarm** (Router-Worker Orchestration âœ…)
- [x] **Phase 8: MCP Integration** (Model Context Protocol âœ…) - *Implemented by [@devalexanderdaza](https://github.com/devalexanderdaza)*
- [ ] **Phase 9: Enterprise Core** (The "Agent OS" Vision)
  - [ ] **Sandbox Environment**: Safe code execution (e.g., E2B or local Docker) for high-risk operations.
  - [ ] **Orchestrated Flows**: Structured, parallel execution pipelines (DAGs) for complex tasks.

## ğŸ”Œ New: MCP (Model Context Protocol) Integration

**Connect to any MCP server!** The agent now supports the [Model Context Protocol](https://modelcontextprotocol.io/), enabling seamless integration with external tools and services.

## ğŸŒ New: External LLM (OpenAI-Compatible) Support

Use any OpenAI-format chat completion endpoint (OpenAI, Azure OpenAI, local Ollama, etc.) to drive the agent with a unified API.

1) Configure environment:
```bash
OPENAI_BASE_URL=https://api.openai.com/v1   # or http://localhost:11434/v1 for Ollama
OPENAI_API_KEY=sk-...                       # leave empty if not required
OPENAI_MODEL=gpt-4o-mini                    # or your preferred model
```
2) Use the tool:
   - Tool name: `call_openai_chat`
   - Args: `prompt` (str), optional `system`, `model`, `temperature`, `max_tokens`.
3) Behavior:
   - Follows standard OpenAI `/chat/completions` schema.
   - Returns the text content of the first choice, or an error message on failure.

### ğŸŒ What is MCP?

MCP is an open protocol that standardizes how AI applications connect to external data sources and tools. With MCP integration, your Antigravity agent can:

- ğŸ”— Connect to multiple MCP servers simultaneously
- ğŸ› ï¸ Use any tools exposed by MCP servers
- ğŸ“Š Access databases, APIs, filesystems, and more
- ğŸ”„ All transparently integrated with local tools

### ğŸš€ Quick Setup

**1. Enable MCP in your `.env`:**
```bash
MCP_ENABLED=true
```

**2. Configure servers in `mcp_servers.json`:**
```json
{
  "servers": [
    {
      "name": "github",
      "transport": "stdio",
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-github"],
      "enabled": true,
      "env": {
        "GITHUB_PERSONAL_ACCESS_TOKEN": "${GITHUB_TOKEN}"
      }
    }
  ]
}
```

**3. Run the agent:**
```bash
python src/agent.py
```

The agent will automatically:
- ğŸ”Œ Connect to configured MCP servers
- ğŸ” Discover available tools
- ğŸ“¦ Register them alongside local tools

### ğŸ—ï¸ Architecture

```mermaid
graph TD
    Agent[ğŸ¤– GeminiAgent] --> LocalTools[ğŸ› ï¸ Local Tools]
    Agent --> MCPManager[ğŸ”Œ MCP Client Manager]
    MCPManager --> Server1[ğŸ“¡ GitHub MCP]
    MCPManager --> Server2[ğŸ“¡ Database MCP]
    MCPManager --> Server3[ğŸ“¡ Custom MCP]
    LocalTools --> |Merged| AllTools[ğŸ“¦ All Available Tools]
    MCPManager --> |Merged| AllTools
```

### ğŸ“¡ Supported Transports

| Transport | Description | Use Case |
|-----------|-------------|----------|
| `stdio` | Standard I/O | Local servers, CLI tools |
| `http` | Streamable HTTP | Remote servers, cloud services |
| `sse` | Server-Sent Events | Legacy HTTP servers |

### ğŸ› ï¸ Built-in MCP Helper Tools

The agent includes helper tools for MCP management:

```python
# List all connected MCP servers
list_mcp_servers()

# List available MCP tools
list_mcp_tools()

# Get help for a specific tool
get_mcp_tool_help("mcp_github_create_issue")

# Check server health
mcp_health_check()
```

### ğŸ“‹ Pre-configured Servers

The `mcp_servers.json` includes ready-to-use configurations for:

- ğŸ—‚ï¸ **Filesystem**: Local file operations
- ğŸ™ **GitHub**: Repository management
- ğŸ—ƒï¸ **PostgreSQL**: Database access
- ğŸ” **Brave Search**: Web search
- ğŸ’¾ **Memory**: Persistent storage
- ğŸŒ **Puppeteer**: Browser automation
- ğŸ’¬ **Slack**: Workspace integration

Just enable the ones you need and add your API keys!

### ğŸ”§ Creating Custom MCP Servers

You can also create your own MCP servers using the [MCP Python SDK](https://github.com/modelcontextprotocol/python-sdk):

```python
from mcp.server.fastmcp import FastMCP

mcp = FastMCP("My Custom Server")

@mcp.tool()
def my_custom_tool(param: str) -> str:
    """A custom tool for your agent."""
    return f"Processed: {param}"

if __name__ == "__main__":
    mcp.run()
```

Then add it to `mcp_servers.json`:

```json
{
  "name": "my-server",
  "transport": "stdio",
  "command": "python",
  "args": ["path/to/my_server.py"],
  "enabled": true
}
```

## ğŸ”¥ New: True Zero-Config Tool & Context Loading

**No more manual imports!** The agent now automatically discovers:

### ğŸ› ï¸ Auto Tool Discovery
Drop any Python file into `src/tools/` and the agent instantly knows how to use it:

```python
# src/tools/my_custom_tool.py
def analyze_sentiment(text: str) -> str:
    """Analyzes the sentiment of given text.
    
    Args:
        text: The text to analyze.
        
    Returns:
        Sentiment score and analysis.
    """
    # Your implementation
    return "Positive sentiment detected!"
```

**That's it!** No need to edit `agent.py`. Just restart and the tool is available.

### ğŸ“š Auto Context Loading
Add knowledge files to `.context/` and they're automatically injected:

```bash
echo "# Project Rules\nUsefriendly language." > .context/project_rules.md
```

The agent will follow these rules immediately on next run.

## ğŸ”¥ New: Multi-Agent Swarm Protocol

**Collaborate at scale!** The swarm enables multiple specialist agents to work together:

### ğŸª Architecture: Router-Worker Pattern

```mermaid
graph TD
    User[User Task] --> Router[ğŸ§­ Router Agent]
    Router --> Coder[ğŸ’» Coder Agent]
    Router --> Reviewer[ğŸ” Reviewer Agent]
    Router --> Researcher[ğŸ“š Researcher Agent]
    Coder --> Router
    Reviewer --> Router
    Researcher --> Router
    Router --> Result[ğŸ“Š Synthesized Result]
```

**Specialist Agents:**
- **Router**: Analyzes tasks, delegates to specialists, synthesizes results
- **Coder**: Writes clean, well-documented code
- **Reviewer**: Checks quality, security, best practices
- **Researcher**: Gathers information and insights

### ğŸš€ Usage

**Run the interactive demo:**
```bash
python -m src.swarm_demo
```

**Use in your code:**
```python
from src.swarm import SwarmOrchestrator

swarm = SwarmOrchestrator()
result = swarm.execute("Build a calculator and review it for security")
print(result)
```

**Example output:**
```
ğŸ§­ [Router] Analyzing task...
ğŸ“¤ [Router â†’ Coder] Build a calculator
ğŸ’» [Coder] Creating calculator implementation...
âœ… [Coder] Done!
ğŸ“¤ [Router â†’ Reviewer] Review for security
ğŸ” [Reviewer] Analyzing code...
âœ… [Reviewer] Review complete!
ğŸ‰ Task Completed!
```
## ğŸ‘¥ Contributors

A massive thank you to the community members who help build this project:


- [@devalexanderdaza](https://github.com/devalexanderdaza) ğŸ’» ğŸ§  **(First Contributor!)**
  - Implemented demo tools script and enhanced agent functionality.
  - Proposed the **"Agent OS" Roadmap** (MCP, Sandbox, Orchestration).
  - Completed the MCP integration setup.
- [@Subham-KRLX](https://github.com/Subham-KRLX) ğŸ’»
  - Added dynamic tools and context loading (Fixes #4)
  - New feature: Add multi-agent cluster protocol (Fixes #6)

**Want to contribute?** Check out our [Issues](https://github.com/study8677/antigravity-workspace-template/issues) page!

## â­ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=study8677/antigravity-workspace-template&type=Date)](https://star-history.com/#study8677/antigravity-workspace-template&Date)

## ğŸ’¡ Call for Ideas: Swarm Protocol

We value **ideas** as much as code! 
We are currently brainstorming the architecture for **Phase 6: Multi-Agent Swarm**. If you provide a solid architectural suggestion or a detailed design that gets adopted, **you will be added to our README as a Contributor**.

Don't hesitate to share your thoughts in the [Issues](https://github.com/study8677/antigravity-workspace-template/issues), even if you don't have time to write the implementation.
